# cs2_case_watcher.py
import os, json, re, hashlib, requests, feedparser
from bs4 import BeautifulSoup

# --- Secrets Ð¸Ð· GitHub â†’ Settings â†’ Secrets and variables â†’ Actions ---
TELEGRAM_TOKEN = os.environ["TELEGRAM_TOKEN"]
CHAT_ID = int(os.environ["CHAT_ID"])

STATE_FILE = "state.json"

# --- RSS-Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ (Ð¼Ð¾Ð¶Ð½Ð¾ Ñ€Ð°ÑÑˆÐ¸Ñ€ÑÑ‚ÑŒ) ---
FEEDS = [
    "https://store.steampowered.com/feeds/news/app/730/?cc=US&l=en",  # Steam News (CS)
    "https://steamdb.info/app/730/patchnotes/rss/",                   # SteamDB patchnotes
    "https://www.reddit.com/r/csgomarketforum/.rss",                  # Reddit CS:GO Market Forum
]

# --- ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°: Ñ„Ð°ÐºÑ‚Ñ‹ + Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ñ‹ (Ð°Ð½Ð³Ð».) ---
KEYWORDS = [
    # Facts (already happened)
    "case removed", "removed from drop", "moved to rare drop",
    "moved to rare", "rare drop pool", "weekly drop",
    "no longer drops", "discontinued case",

    # Predictions / future
    "will be removed", "expected removal", "might be removed",
    "could be removed", "possible removal", "expected to move",
    "might move to rare", "could move to rare",

    # Case names for monitoring (expand as needed)
    "fracture case", "recoil case", "snakebite case", "dreams & nightmares case"
]

# --- ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð¼ Ð³Ð°Ð¹Ð´ Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸ (Ð¿Ð°Ñ€ÑÐ¸Ð¼ HTML Ð¸ ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð´Ð¸Ñ„Ñ„ ÑÐ¿Ð¸ÑÐºÐ¾Ð²) ---
GUIDES = [
    {
        "name": "Steam Guide: CS2 Case Drop Pool",
        "url": "https://steamcommunity.com/sharedfiles/filedetails/?id=2981848978"
    }
]

# ---------- Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ----------
def load_state():
    if os.path.exists(STATE_FILE):
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    # seen: Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÐ½Ð½Ñ‹Ðµ ID Ñ„Ð¸Ð´Ð¾Ð²; guide_hashes: Ñ…ÑÑˆ HTML; guide_cases: Ñ€Ð°ÑÐ¿Ð°Ñ€ÑÐµÐ½Ð½Ñ‹Ðµ ÑÐ¿Ð¸ÑÐºÐ¸ Ð¿Ð¾ ÑÐµÐºÑ†Ð¸ÑÐ¼
    return {"seen": [], "guide_hashes": {}, "guide_cases": {}}

def save_state(state):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def send(text: str):
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    r = requests.post(url, json={"chat_id": CHAT_ID, "text": text, "disable_web_page_preview": True})
    r.raise_for_status()

def norm(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "")).strip().lower()

def fetch_url(url: str) -> str:
    r = requests.get(url, timeout=25, headers={"User-Agent": "Mozilla/5.0"})
    r.raise_for_status()
    return r.text

def hash_text(txt: str) -> str:
    return hashlib.sha256(txt.encode("utf-8", errors="ignore")).hexdigest()

# ---------- ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð³Ð°Ð¹Ð´: Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ ÐºÐµÐ¹ÑÑ‹ Ð¸Ð· Ñ‚Ð°Ð±Ð»Ð¸Ñ† Ð¿Ð¾ ÑÐµÐºÑ†Ð¸ÑÐ¼ ----------
def extract_cases_from_guide(html: str) -> dict:
    """
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ {'active': [...], 'rare': [...], 'unknown': [...]}
    Ð¡ÐµÐºÑ†Ð¸Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÑŽÑ‚ÑÑ Ð¿Ð¾ Ð±Ð»Ð¸Ð¶Ð°Ð¹ÑˆÐ¸Ð¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°Ð¼/Ð¿Ð°Ñ€Ð°Ð³Ñ€Ð°Ñ„Ð°Ð¼.
    """
    soup = BeautifulSoup(html, "html.parser")
    sections = {"active": [], "rare": [], "unknown": []}

    def section_from_text(t: str) -> str:
        t = norm(t)
        if any(k in t for k in ["active weekly", "active drop", "weekly drop", "Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹", "ÐµÐ¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ð¹"]):
            return "active"
        if any(k in t for k in ["rare drop", "rare pool", "Ñ€ÐµÐ´ÐºÐ¸Ð¹", "rare"]):
            return "rare"
        return "unknown"

    current_section = "unknown"
    for tag in soup.find_all(["h1", "h2", "h3", "h4", "p", "table"]):
        if tag.name in ["h1", "h2", "h3", "h4", "p"]:
            txt = tag.get_text(" ", strip=True)
            if txt:
                sec = section_from_text(txt)
                if sec != "unknown":
                    current_section = sec
        if tag.name == "table":
            rows = []
            for tr in tag.find_all("tr"):
                cells = [c.get_text(" ", strip=True) for c in tr.find_all(["td", "th"])]
                if cells:
                    rows.append(cells)
            if rows:
                data_rows = rows[1:] if len(rows) > 1 else rows
                for r in data_rows:
                    if not r:
                        continue
                    case_name = r[0].strip()
                    if not case_name or len(case_name) < 3:
                        continue
                    if case_name not in sections[current_section]:
                        sections[current_section].append(case_name)

    for k in sections:
        sections[k] = sorted(set(sections[k]))
    return sections

# ---------- ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ†Ð¸ÐºÐ» ----------
def run():
    st = load_state()
    seen = set(st.get("seen", []))
    alerts = []

    # 1) RSS-Ð»ÐµÐ½Ñ‚Ñ‹: Ð¸Ñ‰ÐµÐ¼ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ñ„Ñ€Ð°Ð·Ñ‹
    for feed_url in FEEDS:
        feed = feedparser.parse(feed_url)
        for e in feed.entries:
            eid = e.get("id") or e.get("link") or e.get("title")
            if not eid or eid in seen:
                continue
            text = f"{e.get('title','')} {e.get('summary','')}"
            if any(k in norm(text) for k in KEYWORDS):
                alerts.append({
                    "title": (e.get("title") or "(no title)").strip(),
                    "link": e.get("link", feed_url),
                    "pub": e.get("published", "")
                })
            seen.add(eid)

    for item in alerts:
        send(
            "ðŸ”” CS2 update matched keywords\n"
            f"â€¢ Title: {item['title']}\n"
            f"â€¢ Date: {item['pub']}\n"
            f"â€¢ Source: {item['link']}\n"
            "Check drop pool / rare pool context."
        )

    # 2) Ð“Ð°Ð¹Ð´: ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð´Ð¸Ñ„Ñ„ Ñ‚Ð°Ð±Ð»Ð¸Ñ†
    guide_hashes = st.get("guide_hashes", {})
    guide_cases = st.get("guide_cases", {})

    for g in GUIDES:
        try:
            html = fetch_url(g["url"])
            h = hash_text(html)
            guide_hashes[g["url"]] = h

            current = extract_cases_from_guide(html)  # {'active': [...], 'rare': [...], 'unknown': [...]}
            prev = guide_cases.get(g["url"], {"active": [], "rare": [], "unknown": []})

            def diff_lists(new, old):
                s_new, s_old = set(new), set(old)
                added = sorted(s_new - s_old)
                removed = sorted(s_old - s_new)
                return added, removed

            msgs = []
            for sec_key, sec_name in [("active", "Active/Weekly"), ("rare", "Rare"), ("unknown", "Unknown")]:
                add, rem = diff_lists(current.get(sec_key, []), prev.get(sec_key, []))
                if add or rem:
                    part = [f"â€¢ Section **{sec_name}** changed:"]
                    if add:
                        part.append("  + Added: " + ", ".join(add))
                    if rem:
                        part.append("  âˆ’ Removed: " + ", ".join(rem))
                    msgs.append("\n".join(part))

            if msgs:
                send(
                    "ðŸ“„ Steam guide updated (case tables changed)\n"
                    f"â€¢ Source: {g['name']}\n{g['url']}\n\n" +
                    "\n\n".join(msgs)
                )

            guide_cases[g["url"]] = current
        except Exception:
            # ÐÐµ ÑÐ¿Ð°Ð¼Ð¸Ð¼ Ð¾ÑˆÐ¸Ð±ÐºÐ°Ð¼Ð¸ ÑÐµÑ‚Ð¸/Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð°
            pass

    st["seen"] = list(seen)
    st["guide_hashes"] = guide_hashes
    st["guide_cases"] = guide_cases
    save_state(st)

if __name__ == "__main__":
    run()
